"use client";

import { useState } from "react";
import Link from "next/link";
import styles from "./navbar.module.css";
import Image from "next/image";
import UserProfile from "../userProfile/UserProfile";
import InfoWizard from "../InfoWizard/InfoWizard";

const Navbar = () => {
  const [openHelpModal, setOpenHelpModal] = useState(false);
  return (
    <nav className={styles.navbar}>
      <div className={styles.logo}>
        <Link href="/">
          <Image
            src="/logo.png"
            alt="MongoDB logo"
            width={240}
            height={50}
          ></Image>
        </Link>
      </div>

      

      <div className={styles.links}>
        <Link href="/">Demo Overview</Link>
        <Link href="/equipment-criticality-analysis">Equipment Criticality Analysis</Link>
        <Link href="/failure-prediction">Failure Prediction</Link>
        <Link href="/repair-plan-generation">Repair Plan Generation</Link>
      </div>

      <div className="infowizard-container">
  <InfoWizard
    open={openHelpModal}
    setOpen={setOpenHelpModal}
    tooltipText="Tell me more!"
    iconGlyph="Wizard"
    sections={[
      {
        heading: "Instructions and Talk Track",
        content: [
          {
            heading: "Solution Overview",
            body: "This demo showcases the end to end predictive maintenance process. We are essentially chaining AI and Gen AI apps in order to achieve end to end predictive maintenance strategy. The demo consists of 4 steps. At each step, our data input is a mix of structured and unstructured data. We used all the neat services provided by MongoDB Atlas Developer Data Platform such as Vector Search, Stream Processing, change streams and of course the database and aggregations itself. These features enable us to provide right context to the LLM (Cohere with AWS Bedrock) and right data to the ML model (Decision Tree Classifier) and Langchain is used as the app framework gluing everything together.  Finally we get the desired output at each stage starting from machine priority, failure type, repair plan and instructions ",
          },
          {
            heading: "How to Demo",
            body: [
              "Click on Equipment Criticality Analysis to start the first step",
              "Select your AI Provider: Cohere is the only LLM provider this demo is using right now so keep that setting as is",
              "Select the Documents for Analysis: You can click on Preview buttons to see the pdf files of these documents if you wish. Once you have shown these documents to the clients, select all three of them via the checkboxes. Click on Confirm Selection once documents are selected ",
              "Once you click on the Confirm Selection button, the page will display a Q&A tab. For simplicity, you can just click on one of the suggested questions and click on “Ask”. The backend code will vectorize the question, run semantic search and provide context to the Cohere command-r model. The result will be displayed in a couple of seconds along with the data sources used. This is a complete RAG implementation using the MAAP framework. Use this opportunity to explain the benefits of Atlas Vector Search to the clients.               ",
              "The first step is completed and we know that the CNC Milling Machine with ID M0001 is the one that needs to be prioritized. Click on Failure Prediction to start the second step",
              "To start failure prediction, click on “Run Machine and Start Stream Processing” button. In a few seconds, raw and transformed data will appear on screen. Raw data is generated by our machine simulator whereas transformed data is post stream processing. You can highlight the benefits of data transformation via stream processing (strings to floats for example) at this point.",
              "You can also click on “View Live Alerts” which will open up a new tab showing all the machine failures that have been predicted. This application is powered by Change Streams. You can click on a row and acknowledge the alert. This will change the row color to light green.",
              "In the Failure Prediction tab, you can also see a Charts application that shows the total number of alerts and failure types. Highlight the benefits of Atlas Charts here.",
              "The second step is completed and we know that there is more probability of tool wear failure in the Milling machine. Click on Repair Plan Generation to start the third and fourth step",
              "Click on the suggested question about toolwear repair and press Ask. The backend code will vectorize the question, run semantic search and provide context to the Cohere command-r model. The result will be displayed in a couple of seconds along with the data sources used. This is a complete RAG implementation using the MAAP framework. Use this opportunity to explain the benefits of Atlas Vector Search to the clients ",
              "Imagine if we found some service notes that were uploaded to the platform by a technician and they are written in another language (lets say Spanish). We can use RAG architecture again to intelligently merge these service notes with the repair instructions that we generated in the previous step.  To demonstrate this last step, select Spanish from the right column and Click on Confirm Selection. It will take a min but you will see the repair plan being enhanced with technician service notes. This last step concludes this demonstration.",
            ],
          },
        ],
      },
      {
        heading: "Behind the Scenes",
        content: [
          {
            heading: "Logical Architecture",
            body: "",
          },
          {
            image: {
              src: "./demoinfo.png",
              alt: "Conceptual Architecture",
            },
          },
        ],
      },
      {
        heading: "Why MongoDB?",
        content: [
          {
            heading: "Flexible Data Model",
            body: "MongoDB’s document-oriented architecture allows you to store varied data (such as machine data, machine info and inventory data) in a single unified format. This flexibility means you don’t have to redesign your database schema every time your data requirements evolve.",
          },
          {
            heading: "Scalability and Performance",
            body: "MongoDB is designed to scale horizontally, making it capable of handling large volumes of real-time data. This is essential when multiple machines send data simultaneously, ensuring high performance under heavy load.",
          },
          {
            heading: "Real-Time Analytics",
            body: "With powerful aggregation frameworks and change streams, MongoDB supports real-time data analysis and anomaly detection. This enables the system to process incoming data on the fly and quickly surface critical insights.",
          },
          {
            heading: "Seamless Integration with LLM",
            body: "MongoDB is seamlessly integrated with Langchain and AWS Bedrock making it a powerful memory provider.",
          },
          {
            heading: "Vector Search",
            body: "MongoDB Atlas supports native vector search, enabling fast and efficient similarity searches on embedding vectors. This is critical for matching user queries with historical data, thereby enhancing LLM accuracy and providing more relevant recommendations.",
          }
        ],
      },
    ]}
  />
</div>

      <UserProfile></UserProfile>

    
    </nav>
  );
};

export default Navbar;